{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "448a13bd-9e96-4a8b-a0aa-9609185b7013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (1.6.12)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from kaggle) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from kaggle) (4.66.2)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from kaggle) (2.1.0)\n",
      "Requirement already satisfied: bleach in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from bleach->kaggle) (23.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from requests->kaggle) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from requests->kaggle) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65d3ed4-d333-4d66-9496-e983ebdd571b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/aaron7sun/stocknews\n",
      "License(s): CC-BY-NC-SA-4.0\n",
      "stocknews.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d aaron7sun/stocknews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f03dcb-a0b9-4000-8735-fe9749ff525c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
       "      <td>b'This is a busy day:  The European Union has ...</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
       "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
       "      <td>b' Russia has just beaten the United States ov...</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
       "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
       "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
       "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
       "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
       "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
       "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'U.S. troops still in Georgia (did you know t...</td>\n",
       "      <td>b'Why Russias response to Georgia was right'</td>\n",
       "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
       "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
       "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
       "      <td>b'War in Georgia: The Israeli connection'</td>\n",
       "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
       "      <td>b'Christopher King argues that the US and NATO...</td>\n",
       "      <td>b'America: The New Mexico?'</td>\n",
       "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
       "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
       "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
       "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
       "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
       "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
       "      <td>b'Russian forces sink Georgian ships '</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Elephants extinct by 2020?'</td>\n",
       "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
       "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
       "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
       "      <td>b'Israeli defence minister: US against strike ...</td>\n",
       "      <td>b'Gorbachev: We Had No Choice'</td>\n",
       "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
       "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
       "      <td>b'Georgian president  says US military will ta...</td>\n",
       "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>1</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
       "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
       "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
       "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
       "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
       "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
       "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n",
       "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
       "      <td>b'War in the Caucasus is as much the product o...</td>\n",
       "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
       "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
       "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
       "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
       "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
       "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
       "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n",
       "2  2008-08-12      0  b'Remember that adorable 9-year-old who sang a...   \n",
       "3  2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...   \n",
       "4  2008-08-14      1  b'All the experts admit that we should legalis...   \n",
       "\n",
       "                                                Top2  \\\n",
       "0            b'BREAKING: Musharraf to be impeached.'   \n",
       "1        b'Bush puts foot down on Georgian conflict'   \n",
       "2                 b\"Russia 'ends Georgia operation'\"   \n",
       "3  b\"When the president ordered to attack Tskhinv...   \n",
       "4  b'War in South Osetia - 89 pictures made by a ...   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into So...   \n",
       "1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n",
       "2  b'\"If we had no sexual harassment we would hav...   \n",
       "3  b' Israel clears troops who killed Reuters cam...   \n",
       "4  b'Swedish wrestler Ara Abrahamian throws away ...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital...   \n",
       "1  b'Georgian army flees in disarray as Russians ...   \n",
       "2  b\"Al-Qa'eda is losing support in Iraq because ...   \n",
       "3  b'Britain\\'s policy of being tough on drugs is...   \n",
       "4  b'Russia exaggerated the death toll in South O...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. ...   \n",
       "1      b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "2  b'Ceasefire in Georgia: Putin Outmaneuvers the...   \n",
       "3  b'Body of 14 year old found in trunk; Latest (...   \n",
       "4  b'Missile That Killed 9 Inside Pakistan May Ha...   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia...   \n",
       "1  b'What were the Mossad with fraudulent New Zea...   \n",
       "2  b'Why Microsoft and Intel tried to kill the XO...   \n",
       "3  b'China has moved 10 *million* quake survivors...   \n",
       "4  b\"Rushdie Condemns Random House's Refusal to P...   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n",
       "1  b'Russia angered by Israeli military sale to G...   \n",
       "2  b'Stratfor: The Russo-Georgian War and the Bal...   \n",
       "3  b\"Bush announces Operation Get All Up In Russi...   \n",
       "4  b'Poland and US agree to missle defense deal. ...   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but...  ...   \n",
       "1  b'An American citizen living in S.Ossetia blam...  ...   \n",
       "2  b\"I'm Trying to Get a Sense of This Whole Geor...  ...   \n",
       "3             b'Russian forces sink Georgian ships '  ...   \n",
       "4  b'Will the Russians conquer Tblisi? Bet on it,...  ...   \n",
       "\n",
       "                                               Top16  \\\n",
       "0  b'Georgia Invades South Ossetia - if Russia ge...   \n",
       "1  b'Israel and the US behind the Georgian aggres...   \n",
       "2  b'U.S. troops still in Georgia (did you know t...   \n",
       "3                      b'Elephants extinct by 2020?'   \n",
       "4  b'Bank analyst forecast Georgian crisis 2 days...   \n",
       "\n",
       "                                               Top17  \\\n",
       "0                b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1  b'\"Do not believe TV, neither Russian nor Geor...   \n",
       "2       b'Why Russias response to Georgia was right'   \n",
       "3  b'US humanitarian missions soon in Georgia - i...   \n",
       "4  b\"Georgia confict could set back Russia's US r...   \n",
       "\n",
       "                                               Top18  \\\n",
       "0  b'Condoleezza Rice: \"The US would not act to p...   \n",
       "1  b'Riots are still going on in Montreal (Canada...   \n",
       "2  b'Gorbachev accuses U.S. of making a \"serious ...   \n",
       "3             b\"Georgia's DDOS came from US sources\"   \n",
       "4  b'War in the Caucasus is as much the product o...   \n",
       "\n",
       "                                               Top19  \\\n",
       "0  b'This is a busy day:  The European Union has ...   \n",
       "1    b'China to overtake US as largest manufacturer'   \n",
       "2         b'Russia, Georgia, and NATO: Cold War Two'   \n",
       "3  b'Russian convoy heads into Georgia, violating...   \n",
       "4  b'\"Non-media\" photos of South Ossetia/Georgia ...   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n",
       "1                     b'War in South Ossetia [PICS]'   \n",
       "2  b'Remember that adorable 62-year-old who led y...   \n",
       "3  b'Israeli defence minister: US against strike ...   \n",
       "4  b'Georgian TV reporter shot by Russian sniper ...   \n",
       "\n",
       "                                               Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n",
       "1  b'Israeli Physicians Group Condemns State Tort...   \n",
       "2          b'War in Georgia: The Israeli connection'   \n",
       "3                     b'Gorbachev: We Had No Choice'   \n",
       "4  b'Saudi Arabia: Mother moves to block child ma...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  b'Caucasus in crisis: Georgia invades South Os...   \n",
       "1  b' Russia has just beaten the United States ov...   \n",
       "2  b'All signs point to the US encouraging Georgi...   \n",
       "3  b'Witness: Russian forces head towards Tbilisi...   \n",
       "4   b'Taliban wages war on humanitarian aid workers'   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a se...   \n",
       "1  b'Perhaps *the* question about the Georgia - R...   \n",
       "2  b'Christopher King argues that the US and NATO...   \n",
       "3  b' Quarter of Russians blame U.S. for conflict...   \n",
       "4  b'Russia: World  \"can forget about\" Georgia\\'s...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Ban...   \n",
       "1                 b'Russia is so much better at war'   \n",
       "2                        b'America: The New Mexico?'   \n",
       "3  b'Georgian president  says US military will ta...   \n",
       "4  b'Darfur rebels accuse Sudan of mounting major...   \n",
       "\n",
       "                                               Top25  \n",
       "0           b\"No Help for Mexico's Kidnapping Surge\"  \n",
       "1  b\"So this is what it's come to: trading sex fo...  \n",
       "2  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...  \n",
       "3  b'2006: Nobel laureate Aleksander Solzhenitsyn...  \n",
       "4  b'Philippines : Peace Advocate say Muslims nee...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "data = pd.read_csv(\"stocknews/Combined_News_DJIA.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f05b7226-554d-49cf-9143-76240962aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (1989, 27)\n",
      "\n",
      "Column names: Index(['Date', 'Label', 'Top1', 'Top2', 'Top3', 'Top4', 'Top5', 'Top6', 'Top7',\n",
      "       'Top8', 'Top9', 'Top10', 'Top11', 'Top12', 'Top13', 'Top14', 'Top15',\n",
      "       'Top16', 'Top17', 'Top18', 'Top19', 'Top20', 'Top21', 'Top22', 'Top23',\n",
      "       'Top24', 'Top25'],\n",
      "      dtype='object')\n",
      "\n",
      "Data types:\n",
      "Date     object\n",
      "Label     int64\n",
      "Top1     object\n",
      "Top2     object\n",
      "Top3     object\n",
      "Top4     object\n",
      "Top5     object\n",
      "Top6     object\n",
      "Top7     object\n",
      "Top8     object\n",
      "Top9     object\n",
      "Top10    object\n",
      "Top11    object\n",
      "Top12    object\n",
      "Top13    object\n",
      "Top14    object\n",
      "Top15    object\n",
      "Top16    object\n",
      "Top17    object\n",
      "Top18    object\n",
      "Top19    object\n",
      "Top20    object\n",
      "Top21    object\n",
      "Top22    object\n",
      "Top23    object\n",
      "Top24    object\n",
      "Top25    object\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "Date     0\n",
      "Label    0\n",
      "Top1     0\n",
      "Top2     0\n",
      "Top3     0\n",
      "Top4     0\n",
      "Top5     0\n",
      "Top6     0\n",
      "Top7     0\n",
      "Top8     0\n",
      "Top9     0\n",
      "Top10    0\n",
      "Top11    0\n",
      "Top12    0\n",
      "Top13    0\n",
      "Top14    0\n",
      "Top15    0\n",
      "Top16    0\n",
      "Top17    0\n",
      "Top18    0\n",
      "Top19    0\n",
      "Top20    0\n",
      "Top21    0\n",
      "Top22    0\n",
      "Top23    1\n",
      "Top24    3\n",
      "Top25    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the dataset\n",
    "print(\"Shape of the dataset:\", data.shape)\n",
    "\n",
    "# Display the column names\n",
    "print(\"\\nColumn names:\", data.columns)\n",
    "\n",
    "# Check the data types of each column\n",
    "print(\"\\nData types:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f97baa2-75c7-4fb5-a402-8aa28c858101",
   "metadata": {},
   "source": [
    "### It seems we have 3 rows with null values. So, first printing rows that have null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184aa591-7149-4817-891c-619a8d95075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing values in columns Top23, Top24, and Top25:\n",
      "           Date  Label                                               Top1  \\\n",
      "277  2009-09-15      1  b'The Church of Scientology won\\'t be dissolve...   \n",
      "348  2009-12-24      1  b'Woman knocks down Pope Benedict at Christmas...   \n",
      "681  2011-04-21      1  Director of \"Restrepo\" and Photographer Chris ...   \n",
      "\n",
      "                                                  Top2  \\\n",
      "277  b'New virus from rats can kill 80 per cent of ...   \n",
      "348  b'Ugandan President Museveni says he will bloc...   \n",
      "681  Everyone within 20km of Fukushima will be forc...   \n",
      "\n",
      "                                                  Top3  \\\n",
      "277  b'The gruesome spectacle of dolphins being sla...   \n",
      "348  b\"Venezuela's Chavez threatens to kick out car...   \n",
      "681  Bahrain: Activist Zaynab Al-Khawaja's letter t...   \n",
      "\n",
      "                                                  Top4  \\\n",
      "277  b'The End of Innocence in Afghanistan: \\'The G...   \n",
      "348  b'Woman who knocked down pope had pasta in her...   \n",
      "681  More than 80,000 people are claiming incapacit...   \n",
      "\n",
      "                                                  Top5  \\\n",
      "277            b'France approves Internet piracy bill'   \n",
      "348  b'450 people from 21 countries, including 30 f...   \n",
      "681  Libya: 'mission creep' claims as UK sends in m...   \n",
      "\n",
      "                                                  Top6  \\\n",
      "277  b'The Rural Doctors Association says right now...   \n",
      "348  b'Chvez declares Angel Falls is no more: World...   \n",
      "681  Japan considers banning access to evacuation zone   \n",
      "\n",
      "                                                  Top7  \\\n",
      "277  b'Al Jazeera English - Africa - Shabab to aven...   \n",
      "348             b'Drug tests catch out 10 police (UK)'   \n",
      "681  Chinese oil giant Sinopec has stopped exportin...   \n",
      "\n",
      "                                                  Top8  ...  \\\n",
      "277  b\"How Sri Lanka governs through detentions - S...  ...   \n",
      "348  b'Once the worlds fourth-largest lake, the Ara...  ...   \n",
      "681  6.0-magnitude earthquake strikes off east coas...  ...   \n",
      "\n",
      "                                                 Top16  \\\n",
      "277  b'In an equine echo of the controversy surroun...   \n",
      "348  b'Pig farts spark Australia gas scare - I shit...   \n",
      "681  Russian migration official fired in racism row...   \n",
      "\n",
      "                                                 Top17  \\\n",
      "277  b'UPDATE: 5-New York homes raided in terrorism...   \n",
      "348  b'Bin Laden daughter flees to Saudi embassy in...   \n",
      "681  Small amounts of radioactive iodine found in b...   \n",
      "\n",
      "                                                 Top18  \\\n",
      "277  b'Population Growth Impeding Progress on the M...   \n",
      "348  b'Traumatic Brain Injuries:  Growing evidence ...   \n",
      "681  War photographer, Oscar-nominated film directo...   \n",
      "\n",
      "                                                 Top19  \\\n",
      "277    b'Global Population to Reach 7 Billion by 2011'   \n",
      "348  b'The Pakistan Supreme Court has ordered the P...   \n",
      "681  Effeminate boys are being sent to a special ca...   \n",
      "\n",
      "                                                 Top20  \\\n",
      "277                b'Government Funded Feminist Porn '   \n",
      "348  b\"Here's a video the Taliban released this mor...   \n",
      "681  Japan Government Declares 12-Mile Area Around ...   \n",
      "\n",
      "                                                 Top21  \\\n",
      "277  b'Can someone enlighten me re:Holy Land disput...   \n",
      "348               b'Fireworks set off aboard airliner'   \n",
      "681  TEPCO admitted Wednesday that nuclear fuel in ...   \n",
      "\n",
      "                                                 Top22  \\\n",
      "277  b'Human Rights Watch official suspended for co...   \n",
      "348  b'Five VA men may face terrorism charges, Paki...   \n",
      "681  Fukushima evacuees face arrest if they return ...   \n",
      "\n",
      "                                                 Top23 Top24 Top25  \n",
      "277                                                NaN   NaN   NaN  \n",
      "348  b\"Ayatollah Montazeri's Legacy:  In death he m...   NaN   NaN  \n",
      "681          Prince Charles wins some kind of a record   NaN   NaN  \n",
      "\n",
      "[3 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with missing values in columns Top23, Top24, and Top25\n",
    "missing_rows = data[data[['Top23', 'Top24', 'Top25']].isnull().any(axis=1)]\n",
    "\n",
    "# Print the rows with missing values\n",
    "print(\"Rows with missing values in columns Top23, Top24, and Top25:\")\n",
    "print(missing_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d37e1ef6-e793-4aae-b731-3e91445a4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in columns Top23, Top24, and Top25 with empty strings\n",
    "data[['Top23', 'Top24', 'Top25']] = data[['Top23', 'Top24', 'Top25']].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab699e-6ce9-483a-99d0-e5c4c5c3b1a0",
   "metadata": {},
   "source": [
    "### Combining all the headlines for each day into a single text entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8315b1b4-0833-4b06-9e06-8c0c5e459bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['combined_headlines'] = data.iloc[:,2:].apply(lambda row: ' '.join([str(headline) for headline in row]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a35f5169-1513-4a25-88c0-5350b34b5468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>combined_headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                 combined_headlines\n",
       "0  2008-08-08  b\"Georgia 'downs two Russian warplanes' as cou...\n",
       "1  2008-08-11  b'Why wont America and Nato help us? If they w...\n",
       "2  2008-08-12  b'Remember that adorable 9-year-old who sang a...\n",
       "3  2008-08-13  b' U.S. refuses Israel weapons to attack Iran:...\n",
       "4  2008-08-14  b'All the experts admit that we should legalis..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Date','combined_headlines']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69754398-afc4-420f-acb3-b236cd7b9d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from nltk) (2024.4.28)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac89c45-b120-47d9-821a-4b3b4e96feb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f01bba6-51ab-4a33-92aa-ad2f40f5d3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12ed62e5-08fc-4678-8c36-b3325d00052e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    pre_processed_text = ' '.join(tokens)\n",
    "    return pre_processed_text\n",
    "\n",
    "data['preprocessed_headlines'] = data['combined_headlines'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8be24f2-7778-4662-9ce7-94c434e58894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date                             preprocessed_headlines\n",
      "0  2008-08-08  b georgia down two russian warplan countri mov...\n",
      "1  2008-08-11  b wont america nato help us wont help us help ...\n",
      "2  2008-08-12  b rememb ador 9 year old sang open ceremoni fa...\n",
      "3  2008-08-13  b u refus israel weapon attack iran report b p...\n",
      "4  2008-08-14  b expert admit legalis drug b war south osetia...\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the preprocessed text\n",
    "print(data[['Date', 'preprocessed_headlines']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dec7aea-3181-4123-a29c-62be1e64ef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1591, 29)\n",
      "Testing set shape: (398, 29)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Spliting the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Displaying the shapes of the training and testing sets\n",
    "print(\"Training set shape:\", train_data.shape)\n",
    "print(\"Testing set shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35b70759-be7e-4154-98ab-d19a5f914a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (4.40.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbd351cb-5ac7-4ca8-b187-11dcae478314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd3d2b6c-7cb7-40db-b27d-f45edf49c0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0+cpu'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92f0e7e5-7211-4e93-a17e-9d99e4664c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "631188c1-53a3-4199-ae9e-167d6cf63c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(train_data['preprocessed_headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7568bd1a-ee34-4221-914f-17ded4020ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "#Loading the pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Loading the pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "128c37cd-ccdf-4953-ae87-415fcb57412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the input text data for training set\n",
    "train_inputs = tokenizer(list(train_data['preprocessed_headlines']), padding = True, truncation = True, return_tensors='pt')\n",
    "\n",
    "# Tokenize the input text data for testing set\n",
    "test_inputs = tokenizer(list(test_data['preprocessed_headlines']), padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b35afcc-579a-413f-ba82-ab7474ec9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aa4095-07af-432b-9032-30921602c5e5",
   "metadata": {},
   "source": [
    "### Now that we have tokenized the input data, we'll prepare the input data in the required format for the BERT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d152a2a-7dec-4acc-8c1f-be91cbd038d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the input data in the required format for training set\n",
    "train_labels = torch.tensor(train_data['Label'].values)\n",
    "train_dataset = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'], train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a2c5977-1964-4039-aa2d-e745827f2cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the input data in the required format for testing set\n",
    "test_labels = torch.tensor(test_data['Label'].values)\n",
    "test_dataset = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'], test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f709051-a67a-4e8b-936e-07ce94b851c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        return outputs.logits\n",
    "\n",
    "num_classes = 2\n",
    "model = SentimentClassifier(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53c3a6ab-d43a-407e-9f97-89f505122ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "learning_rate = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5c91827-d6dd-403e-b08a-3e121802828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d68423c6-a1cc-4e4f-b1cc-60d736029dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.6990\n",
      "Epoch 2/3, Loss: 0.6964\n",
      "Epoch 3/3, Loss: 0.6966\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# DataLoader for training dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a40c21-167c-4f08-a40c-7e004b35dcac",
   "metadata": {},
   "source": [
    "### We are now saving our model so that we can further fine-tune it more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba85561f-4934-4384-a2c8-bbacd37b9986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the file path to save the model\n",
    "model_path = 'model/bert_sentiment_model.pth'\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0023caff-ac0c-41f7-9af0-c9845327211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5704\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.00      0.00      0.00       171\n",
      "    Positive       0.57      1.00      0.73       227\n",
      "\n",
      "    accuracy                           0.57       398\n",
      "   macro avg       0.29      0.50      0.36       398\n",
      "weighted avg       0.33      0.57      0.41       398\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\sahil\\.conda\\envs\\pythonenv2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# DataLoader for testing dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        predicted_labels = torch.argmax(logits, dim=1)\n",
    "        predictions.extend(predicted_labels.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=['Negative', 'Positive']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47888b1-77fb-4259-a26b-6952500bd05a",
   "metadata": {},
   "source": [
    "### This shows that our model perform better on positive sentiments but very poor on negative sentiments for our dataset.\n",
    "### So lets fine-tune our hyperparameters more "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19664f94-4c35-4073-86e7-ac29723fd639",
   "metadata": {},
   "source": [
    "### Now, we will perform RandmoSearchCV to evaluate the best hyperparameters for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee24d7dd-875e-40c3-9a00-64cbc0aa4175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'estimator' parameter of RandomizedSearchCV must be an object implementing 'fit'. Got <function bert_model at 0x000001CC03EAFF70> instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator\u001b[38;5;241m=\u001b[39mbert_model, param_distributions\u001b[38;5;241m=\u001b[39mparam_grid, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Perform random search\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Print the best parameters and best accuracy found\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pythonenv2\\lib\\site-packages\\sklearn\\base.py:1467\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1462\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1463\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1464\u001b[0m )\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1467\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[0;32m   1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\pythonenv2\\lib\\site-packages\\sklearn\\base.py:666\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    659\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \n\u001b[0;32m    661\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 666\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\pythonenv2\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m     )\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'estimator' parameter of RandomizedSearchCV must be an object implementing 'fit'. Got <function bert_model at 0x000001CC03EAFF70> instead."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import BertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "# Define the parameter grid for random search\n",
    "param_grid = {\n",
    "    'learning_rate': [5e-5, 3e-5, 2e-5],\n",
    "    'num_epochs': [3, 4, 5],\n",
    "    'batch_size': [8, 16, 32]\n",
    "}\n",
    "\n",
    "def bert_model(learning_rate, num_epochs, batch_size, train_features, train_labels, test_features, test_labels):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    num_classes = 2\n",
    "    \n",
    "    train_dataset = TensorDataset(train_features['input_ids'], train_features['attention_mask'], train_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    test_dataset = TensorDataset(test_features['input_ids'], test_features['attention_mask'], test_labels)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16)\n",
    "    \n",
    "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            predictions.extend(predicted.tolist())\n",
    "    accuracy = accuracy_score(test_labels.numpy(), predictions)\n",
    "    return accuracy\n",
    "\n",
    "# Create RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=bert_model, param_distributions=param_grid, n_iter=10, cv=3, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Perform random search\n",
    "random_search.fit(train_inputs, train_labels)\n",
    "\n",
    "# Print the best parameters and best accuracy found\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best accuracy found:\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3512a-619e-4588-998e-f4cf172aecb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
